{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl-ZJr1ajG_N",
        "outputId": "ba9f144c-b88f-4635-d400-a62a9f53e8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.29)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Installing collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.9\n"
          ]
        }
      ],
      "source": [
        "pip install pandas psycopg2-binary sqlalchemy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chardet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjtPSH2d657M",
        "outputId": "0787cfb2-2b56-4633-8c17-076cce775df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Étape 2: Télécharger les fichiers\n",
        "url1 = \"https://www.data.gouv.fr/fr/datasets/r/5cb21a85-b0b0-4a65-a249-806a040ec372\"\n",
        "url2 = \"https://www.data.gouv.fr/fr/datasets/r/b7bd49cd-904c-4c5d-b60f-018b51df9b0e\"\n",
        "\n",
        "file1 = pd.read_csv(url1)\n",
        "file2 = pd.read_csv(url2)\n",
        "\n",
        "print(file1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "C1qXvXlvPToj",
        "outputId": "df45e881-0758-4761-d943-6b0971bdfa75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 1 fields in line 14, saw 3\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-42bec769042e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0murl2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.data.gouv.fr/fr/datasets/r/b7bd49cd-904c-4c5d-b60f-018b51df9b0e\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfile1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mfile2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 14, saw 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import chardet\n",
        "import requests\n",
        "\n",
        "# Étape 2: Télécharger les fichiers\n",
        "url1 = \"https://www.data.gouv.fr/fr/datasets/r/5cb21a85-b0b0-4a65-a249-806a040ec372\"\n",
        "url2 = \"https://www.data.gouv.fr/fr/datasets/r/b7bd49cd-904c-4c5d-b60f-018b51df9b0e\"\n",
        "url3 = \"https://www.data.gouv.fr/fr/datasets/r/dc2fd531-2314-44bb-b0a9-39e621e4b12c\"\n",
        "url4 = \"https://www.data.gouv.fr/fr/datasets/r/2b1523f0-d8bf-426f-bf1f-9974c9cccb53\"\n",
        "\n",
        "# Télécharger une petite partie du fichier pour détecter l'encodage\n",
        "response = requests.get(url4)\n",
        "detected_encoding = chardet.detect(response.content[:10000])  # Analyser seulement les premiers 1000 octets\n",
        "\n",
        "# Afficher l'encodage détecté\n",
        "print(detected_encoding)\n",
        "\n",
        "try:\n",
        "    file1 = pd.read_csv(url1, sep=\";\", header=0, encoding='utf8')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Erreur lors de la lecture du fichier 1 : {e}\")\n",
        "\n",
        "try:\n",
        "    file2 = pd.read_csv(url2, sep=\",\", header=0, encoding='ISO-8859-1')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Erreur lors de la lecture du fichier 2 : {e}\")\n",
        "\n",
        "try:\n",
        "    file3 = pd.read_csv(url3, sep=\",\", header=0, encoding='utf-8-sig')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Erreur lors de la lecture du fichier 2 : {e}\")\n",
        "\n",
        "try:\n",
        "    file4 = pd.read_csv(url4, sep=\",\", header=0, encoding='windows-1252')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Erreur lors de la lecture du fichier 2 : {e}\")\n",
        "\n",
        "# Afficher les premières lignes du fichier pour vérifier\n",
        "print(file1.head())\n",
        "print(file2.head())\n",
        "print(file3.head())\n",
        "print(file4.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9wsLhAQyPvj",
        "outputId": "aab8c26a-5d27-4334-ff85-672a8fd9ee5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'encoding': 'ascii', 'confidence': 1.0, 'language': ''}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-acabc65b2c40>:31: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  file3 = pd.read_csv(url3, sep=\",\", header=0, encoding='utf-8-sig')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    gid                                                nom arrete_pref_numero  \\\n",
            "0  2727  Centre de vaccination - Parc d'activité Saint-...                NaN   \n",
            "1  3296                             Test_sauve_mon_vaccin4                NaN   \n",
            "2  2531                                         UHSI Lille                NaN   \n",
            "3  1244                     Centre de Vaccination - EVRON-                NaN   \n",
            "4   440  Centre de Vaccination - MAYENNE - Salle polyva...                NaN   \n",
            "\n",
            "   xy_precis            id_adr            adr_num                   adr_voie  \\\n",
            "0   1.000000  95572_0225_00019                 19     Avenue de l’Eguillette   \n",
            "1   1.000000  13215_6459_00040                 40    Avenue de Saint Antoine   \n",
            "2   0.999994  59350_6513_00005                  5       Avenue Oscar Lambret   \n",
            "3   1.000000  53097_1500_00013  Gymnase municipal  Boulevard Henri Rossignol   \n",
            "4   0.999998  53147_1810_00329                NaN                 Rue Volney   \n",
            "\n",
            "    com_cp com_insee              com_nom  ...  date_ouverture  \\\n",
            "0  95310.0     95572  Saint-Ouen-l'Aumône  ...      2021-07-12   \n",
            "1  13015.0     13215            Marseille  ...             NaN   \n",
            "2  59000.0     59350                Lille  ...             NaN   \n",
            "3  53600.0     53097                Évron  ...      2021-01-26   \n",
            "4  53100.0     53147              Mayenne  ...      2021-01-18   \n",
            "\n",
            "                                        rdv_site_web       rdv_tel rdv_tel2  \\\n",
            "0                                                NaN           NaN      NaN   \n",
            "1                                                NaN           NaN      NaN   \n",
            "2                                                NaN           NaN      NaN   \n",
            "3  https://partners.doctolib.fr/etablissement-de-...  +33243535300      NaN   \n",
            "4  https://partners.doctolib.fr/maison-de-sante/m...  +33243535300      NaN   \n",
            "\n",
            "      rdv_modalites  rdv_consultation_prevaccination centre_svi_repondeur  \\\n",
            "0  sans Rendez-vous                              NaN                  NaN   \n",
            "1               NaN                              NaN                  NaN   \n",
            "2               NaN                              NaN                  NaN   \n",
            "3               NaN                                t                  NaN   \n",
            "4               NaN                                t                  NaN   \n",
            "\n",
            "   centre_fermeture reserve_professionels_sante               centre_type  \n",
            "0                 t                         NaN                       NaN  \n",
            "1                 t                         NaN                       NaN  \n",
            "2                 t                         NaN                    {UHSI}  \n",
            "3                 t                         NaN                       NaN  \n",
            "4                 t                         NaN  {\"Vaccination 5-11 ans\"}  \n",
            "\n",
            "[5 rows x 43 columns]\n",
            "   id_centre date_debut_semaine  code_region nom_region code_departement  \\\n",
            "0       1001         2021-08-16           93        PAC               04   \n",
            "1       1001         2021-08-23           93        PAC               04   \n",
            "2       1003         2021-08-16           93        PAC               04   \n",
            "3       1003         2021-08-23           93        PAC               04   \n",
            "4       1004         2021-08-16           11        IDF               93   \n",
            "\n",
            "           nom_departement commune_insee  \\\n",
            "0  Alpes-de-Haute-Provence         04070   \n",
            "1  Alpes-de-Haute-Provence         04070   \n",
            "2  Alpes-de-Haute-Provence         04112   \n",
            "3  Alpes-de-Haute-Provence         04112   \n",
            "4        Seine-Saint-Denis         93029   \n",
            "\n",
            "                                        nom_centre  nombre_ucd  \\\n",
            "0                               Palais des Congrès         300   \n",
            "1                               Palais des Congrès         300   \n",
            "2                               Salle Osco Manosco         350   \n",
            "3                               Salle Osco Manosco         350   \n",
            "4  Centre de vaccination - Espace culturel du Parc         299   \n",
            "\n",
            "   doses_allouees  rdv_pris  \n",
            "0            1800      1714  \n",
            "1            1800      1310  \n",
            "2            2100      1574  \n",
            "3            2100      1780  \n",
            "4            1794      2417  \n",
            "   code_region region departement id_centre  \\\n",
            "0           84    ARA          07        NR   \n",
            "1           84    ARA          07        NR   \n",
            "2           84    ARA          07        NR   \n",
            "3           84    ARA          07        NR   \n",
            "4           84    ARA          07        NR   \n",
            "\n",
            "                            nom_centre  rang_vaccinal date_debut_semaine  \\\n",
            "0  ADMR Centre de Santé \"Les Cévennes\"              1         2021-08-02   \n",
            "1  ADMR Centre de Santé \"Les Cévennes\"              2         2021-08-02   \n",
            "2  ADMR Centre de Santé \"Les Cévennes\"              1         2021-08-09   \n",
            "3  ADMR Centre de Santé \"Les Cévennes\"              2         2021-08-09   \n",
            "4  ADMR Centre de Santé \"Les Cévennes\"              1         2021-08-16   \n",
            "\n",
            "     nb  nb_rdv_cnam  nb_rdv_rappel  \n",
            "0  2063            0              0  \n",
            "1   943            0              0  \n",
            "2  1981            0              0  \n",
            "3  2514            0              0  \n",
            "4  1155            0              0  \n",
            "  code_departement departement                       raison_sociale  \\\n",
            "0               01         Ain                          CH FLEYRIAT   \n",
            "1               01         Ain                          CH FLEYRIAT   \n",
            "2               01         Ain                          CH FLEYRIAT   \n",
            "3               01         Ain                          CH FLEYRIAT   \n",
            "4               02       Aisne  CENTRE HOSPITALIER DE SAINT QUENTIN   \n",
            "\n",
            "                              libelle_pui     finess         type_de_vaccin  \\\n",
            "0  PUI CENTRE HOSPITALIER BOURG EN BRESSE  010000024  Pfizer P<e9>diatrique   \n",
            "1  PUI CENTRE HOSPITALIER BOURG EN BRESSE  010000024            Moderna BA1   \n",
            "2  PUI CENTRE HOSPITALIER BOURG EN BRESSE  010000024             Pifzer BA5   \n",
            "3  PUI CENTRE HOSPITALIER BOURG EN BRESSE  010000024              Nuvaxovid   \n",
            "4                 PUI de CH SAINT-QUENTIN  020000162                Janssen   \n",
            "\n",
            "   nb_ucd  nb_doses        date  \n",
            "0    1373     13730  2023-02-22  \n",
            "1       9         9  2023-02-22  \n",
            "2     271      1626  2023-02-22  \n",
            "3     471      4710  2023-02-22  \n",
            "4       9        45  2023-02-22  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, MetaData, Table, String, Integer, Float, Boolean, Date, DateTime\n",
        "from sqlalchemy.dialects.postgresql import BYTEA\n",
        "from sqlalchemy.sql.sqltypes import NullType\n",
        "\n",
        "# Fonction pour déduire le type de colonne SQLAlchemy à partir des données pandas\n",
        "def dtype_to_sqlalchemy_type(dtype):\n",
        "    if pd.api.types.is_integer_dtype(dtype):\n",
        "        return Integer()\n",
        "    elif pd.api.types.is_float_dtype(dtype):\n",
        "        return Float()\n",
        "    elif pd.api.types.is_bool_dtype(dtype):\n",
        "        return Boolean()\n",
        "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
        "        return DateTime()\n",
        "    elif pd.api.types.is_string_dtype(dtype):\n",
        "        return String()\n",
        "    else:\n",
        "        return NullType()\n",
        "\n",
        "# Fonction pour générer le script SQL de création de table\n",
        "def generate_create_table_script(df, table_name):\n",
        "    metadata = MetaData()\n",
        "    columns = []\n",
        "    for column_name, dtype in df.dtypes.iteritems():\n",
        "        column_type = dtype_to_sqlalchemy_type(dtype)\n",
        "        columns.append(column_name)\n",
        "        columns.append(column_type)\n",
        "    table = Table(table_name, metadata, *columns)\n",
        "    return str(table.compile(dialect=engine.dialect))\n",
        "\n",
        "# Remplacez 'postgresql://user:password@localhost:5432/mydatabase' par votre URL de connexion\n",
        "engine = create_engine('postgresql://user:password@localhost:5432/mydatabase')\n",
        "\n",
        "# Lire les fichiers CSV\n",
        "url1 = \"https://www.data.gouv.fr/fr/datasets/r/5cb21a85-b0b0-4a65-a249-806a040ec372\"\n",
        "url2 = \"https://www.data.gouv.fr/fr/datasets/r/b7bd49cd-904c-4c5d-b60f-018b51df9b0e\"\n",
        "\n",
        "df1 = pd.read_csv(url1, encoding='ISO-8859-1')\n",
        "df2 = pd.read_csv(url2, encoding='ISO-8859-1')\n",
        "\n",
        "# Générer les scripts SQL\n",
        "script1 = generate_create_table_script(df1, 'table_name_1')\n",
        "script2 = generate_create_table_script(df2, 'table_name_2')\n",
        "\n",
        "print(script1)\n",
        "print(script2)"
      ],
      "metadata": {
        "id": "xrP5VUztbHOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dbt --no-cache-dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiY9luUgyMor",
        "outputId": "5ad35d2a-8e37-4807-93e1-af82f0593feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dbt\n",
            "  Downloading dbt-1.0.0.37.4.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=61.2 in /usr/local/lib/python3.10/dist-packages (from dbt) (67.7.2)\n",
            "Building wheels for collected packages: dbt\n",
            "  Building wheel for dbt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dbt: filename=dbt-1.0.0.37.4-py3-none-any.whl size=1870 sha256=bf79812ad1132a411c15eef831867db8173278f6c92c48415269ea68bd7351cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zfj672_i/wheels/e1/d2/8a/735fe3d7f83191a37a5b0bfbe49881aca48dd940f975099500\n",
            "Successfully built dbt\n",
            "Installing collected packages: dbt\n",
            "Successfully installed dbt-1.0.0.37.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install snowflake"
      ],
      "metadata": {
        "id": "bHTrAu08yJCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0258e10-8760-4145-c20f-82d70c9316e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snowflake\n",
            "  Downloading snowflake-0.7.0-py3-none-any.whl (1.5 kB)\n",
            "Collecting snowflake-core==0.7.0 (from snowflake)\n",
            "  Downloading snowflake_core-0.7.0-py3-none-any.whl (330 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting snowflake-legacy (from snowflake)\n",
            "  Downloading snowflake_legacy-0.7.0-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: atpublic>=4 in /usr/local/lib/python3.10/dist-packages (from snowflake-core==0.7.0->snowflake) (4.1.0)\n",
            "Requirement already satisfied: pydantic>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from snowflake-core==0.7.0->snowflake) (2.6.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from snowflake-core==0.7.0->snowflake) (2.8.2)\n",
            "Collecting snowflake-snowpark-python<2.0.0,>=1.5.0 (from snowflake-core==0.7.0->snowflake)\n",
            "  Downloading snowflake_snowpark_python-1.14.0-py3-none-any.whl (419 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.7/419.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from snowflake-core==0.7.0->snowflake) (2.0.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.7->snowflake-core==0.7.0->snowflake) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.7->snowflake-core==0.7.0->snowflake) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.7->snowflake-core==0.7.0->snowflake) (4.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->snowflake-core==0.7.0->snowflake) (1.16.0)\n",
            "Requirement already satisfied: setuptools>=40.6.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (0.43.0)\n",
            "Collecting snowflake-connector-python<4.0.0,>=3.6.0 (from snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake)\n",
            "  Downloading snowflake_connector_python-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (6.0.1)\n",
            "Requirement already satisfied: cloudpickle!=2.1.0,!=2.2.0,<=2.2.1,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2.2.1)\n",
            "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (1.16.0)\n",
            "Requirement already satisfied: cryptography<43.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (42.0.5)\n",
            "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (24.1.0)\n",
            "Requirement already satisfied: pyjwt<3.0.0 in /usr/lib/python3/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2.3.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2023.4)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2024.2.2)\n",
            "Requirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (3.13.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2.4.0)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (4.2.0)\n",
            "Collecting tomlkit (from snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake)\n",
            "  Downloading tomlkit-0.12.4-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python<4.0.0,>=3.6.0->snowflake-snowpark-python<2.0.0,>=1.5.0->snowflake-core==0.7.0->snowflake) (2.22)\n",
            "Installing collected packages: asn1crypto, tomlkit, snowflake-legacy, snowflake-connector-python, snowflake-snowpark-python, snowflake-core, snowflake\n",
            "Successfully installed asn1crypto-1.5.1 snowflake-0.7.0 snowflake-connector-python-3.8.0 snowflake-core-0.7.0 snowflake-legacy-0.7.0 snowflake-snowpark-python-1.14.0 tomlkit-0.12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import snowflake.connector\n",
        "from snowflake.connector.pandas_tools import write_pandas\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Créer une connexion à Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    user=userdata.get('SNOWFLAKE_USER'),\n",
        "    password=userdata.get('SNOWFLAKE_PASSWORD'),\n",
        "    account=userdata.get('SNOWFLAKE_ACCOUNT'),\n",
        "    warehouse=userdata.get('SNOWFLAKE_WAREHOUSE'),\n",
        "    database=userdata.get('SNOWFLAKE_DATABASE'),\n",
        "    schema=userdata.get('SNOWFLAKE_SCHEMA')\n",
        ")\n",
        "\n",
        "# Fonction pour charger un DataFrame dans Snowflake\n",
        "def load_dataframe_to_snowflake(df, table_name):\n",
        "    success, nchunks, nrows, _ = write_pandas(conn, df, table_name.upper(), auto_create_table=True)\n",
        "    print(f\"Chargement réussi de {nrows} lignes dans la table {table_name}.\")\n",
        "\n",
        "# Télécharger les fichiers et les charger dans Snowflake\n",
        "urls = [\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/5cb21a85-b0b0-4a65-a249-806a040ec372\",\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/b7bd49cd-904c-4c5d-b60f-018b51df9b0e\",\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/dc2fd531-2314-44bb-b0a9-39e621e4b12c\",\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/2b1523f0-d8bf-426f-bf1f-9974c9cccb53\"\n",
        "]\n",
        "\n",
        "encodings = ['utf8', 'ISO-8859-1', 'utf-8-sig', 'windows-1252']\n",
        "separators = [';', ',', ',', ',']\n",
        "files_names = [\"centres_vaccinations\",\"allocations_vs_rdv\",\"prise_rdv_par_centre\",\"stock\"]\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "    try:\n",
        "        df = pd.read_csv(url, sep=separators[i], header=0, encoding=encodings[i], dtype={'departement': str})\n",
        "        table_name = files_names[i]\n",
        "        load_dataframe_to_snowflake(df, table_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors de la lecture ou du chargement du fichier {i+1} : {e}\")\n",
        "\n",
        "# Fermer la connexion\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R008lyqNxluD",
        "outputId": "55d0614c-70bd-466e-defc-1587b276cc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erreur lors de la lecture ou du chargement du fichier 1 : 000904 (42000): SQL compilation error: error line 1 at position 95\n",
            "invalid identifier '\"gid\"'\n",
            "Erreur lors de la lecture ou du chargement du fichier 2 : 000904 (42000): SQL compilation error: error line 1 at position 93\n",
            "invalid identifier '\"id_centre\"'\n",
            "Erreur lors de la lecture ou du chargement du fichier 3 : 000904 (42000): SQL compilation error: error line 1 at position 95\n",
            "invalid identifier '\"code_region\"'\n",
            "Erreur lors de la lecture ou du chargement du fichier 4 : 000904 (42000): SQL compilation error: error line 1 at position 80\n",
            "invalid identifier '\"code_departement\"'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import snowflake.connector\n",
        "from snowflake.connector.pandas_tools import write_pandas\n",
        "from google.colab import userdata\n",
        "\n",
        "# Créer une connexion à Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    user=userdata.get('SNOWFLAKE_USER'),\n",
        "    password=userdata.get('SNOWFLAKE_PASSWORD'),\n",
        "    account=userdata.get('SNOWFLAKE_ACCOUNT'),\n",
        "    warehouse=userdata.get('SNOWFLAKE_WAREHOUSE'),\n",
        "    database=userdata.get('SNOWFLAKE_DATABASE'),\n",
        "    schema=userdata.get('SNOWFLAKE_SCHEMA')\n",
        ")\n",
        "\n",
        "# Fonction pour charger un DataFrame dans Snowflake\n",
        "def load_dataframe_to_snowflake(df, table_name):\n",
        "    print(f\"Starting to load data into {table_name}...\")\n",
        "    success, nchunks, nrows, _ = write_pandas(conn, df, table_name.upper(), auto_create_table=True)\n",
        "    if success:\n",
        "        print(f\"Chargement réussi de {nrows} lignes dans la table {table_name}.\")\n",
        "    else:\n",
        "        print(f\"Failed to load data into {table_name}.\")\n",
        "\n",
        "# Télécharger les fichiers et les charger dans Snowflake\n",
        "urls = [\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/5cb21a85-b0b0-4a65-a249-806a040ec372\",\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/b7bd49cd-904c-4c5d-b60f-018b51df9b0e\",\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/dc2fd531-2314-44bb-b0a9-39e621e4b12c\",\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/2b1523f0-d8bf-426f-bf1f-9974c9cccb53\"\n",
        "]\n",
        "\n",
        "encodings = ['utf8', 'ISO-8859-1', 'utf-8-sig', 'windows-1252']\n",
        "separators = [';', ',', ',', ',']\n",
        "files_names = [\"centres_vaccinations\", \"allocations_vs_rdv\", \"prise_rdv_par_centre\", \"stock\"]\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "    try:\n",
        "        print(f\"Reading CSV file from {url}\")\n",
        "        df = pd.read_csv(url, sep=separators[i], header=0, encoding=encodings[i], dtype={'departement': str})\n",
        "        print(f\"CSV file read successfully. DataFrame shape: {df.shape}\")\n",
        "\n",
        "        table_name = files_names[i]\n",
        "        load_dataframe_to_snowflake(df, table_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors de la lecture ou du chargement du fichier {i+1} : {e}\")\n",
        "\n",
        "# Fermer la connexion\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5yDroKs5F5U",
        "outputId": "d7c06519-7bf2-4163-d61d-24cb93fdb4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading CSV file from https://www.data.gouv.fr/fr/datasets/r/5cb21a85-b0b0-4a65-a249-806a040ec372\n",
            "CSV file read successfully. DataFrame shape: (3211, 43)\n",
            "Starting to load data into centres_vaccinations...\n",
            "Erreur lors de la lecture ou du chargement du fichier 1 : 000904 (42000): SQL compilation error: error line 1 at position 95\n",
            "invalid identifier '\"gid\"'\n",
            "Reading CSV file from https://www.data.gouv.fr/fr/datasets/r/b7bd49cd-904c-4c5d-b60f-018b51df9b0e\n",
            "CSV file read successfully. DataFrame shape: (3564, 11)\n",
            "Starting to load data into allocations_vs_rdv...\n",
            "Erreur lors de la lecture ou du chargement du fichier 2 : 000904 (42000): SQL compilation error: error line 1 at position 93\n",
            "invalid identifier '\"id_centre\"'\n",
            "Reading CSV file from https://www.data.gouv.fr/fr/datasets/r/dc2fd531-2314-44bb-b0a9-39e621e4b12c\n",
            "CSV file read successfully. DataFrame shape: (99405, 10)\n",
            "Starting to load data into prise_rdv_par_centre...\n",
            "Erreur lors de la lecture ou du chargement du fichier 3 : 000904 (42000): SQL compilation error: error line 1 at position 95\n",
            "invalid identifier '\"code_region\"'\n",
            "Reading CSV file from https://www.data.gouv.fr/fr/datasets/r/2b1523f0-d8bf-426f-bf1f-9974c9cccb53\n",
            "CSV file read successfully. DataFrame shape: (749, 9)\n",
            "Starting to load data into stock...\n",
            "Erreur lors de la lecture ou du chargement du fichier 4 : 000904 (42000): SQL compilation error: error line 1 at position 80\n",
            "invalid identifier '\"code_departement\"'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import snowflake.connector\n",
        "from snowflake.connector.pandas_tools import write_pandas\n",
        "from google.colab import userdata\n",
        "\n",
        "# Créer une connexion à Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    user=userdata.get('SNOWFLAKE_USER'),\n",
        "    password=userdata.get('SNOWFLAKE_PASSWORD'),\n",
        "    account=userdata.get('SNOWFLAKE_ACCOUNT'),\n",
        "    warehouse=userdata.get('SNOWFLAKE_WAREHOUSE'),\n",
        "    database=userdata.get('SNOWFLAKE_DATABASE'),\n",
        "    schema=userdata.get('SNOWFLAKE_SCHEMA')\n",
        ")\n",
        "\n",
        "# Fonction pour charger un DataFrame dans Snowflake\n",
        "def load_dataframe_to_snowflake(df, table_name):\n",
        "    # Remove double quotes from column names to avoid case-sensitivity issues\n",
        "    df.columns = [col.replace('\"', '') for col in df.columns]\n",
        "\n",
        "    # Convert column names to uppercase because Snowflake column names are uppercase by default\n",
        "    df.columns = df.columns.str.upper()\n",
        "\n",
        "    success, nchunks, nrows, _ = write_pandas(conn, df, table_name.upper(), auto_create_table=True)\n",
        "    print(f\"Chargement réussi de {nrows} lignes dans la table {table_name}.\")\n",
        "\n",
        "# Télécharger les fichiers et les charger dans Snowflake\n",
        "urls = [\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/5cb21a85-b0b0-4a65-a249-806a040ec372\",\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/b7bd49cd-904c-4c5d-b60f-018b51df9b0e\",\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/dc2fd531-2314-44bb-b0a9-39e621e4b12c\",\n",
        "    \"https://www.data.gouv.fr/fr/datasets/r/2b1523f0-d8bf-426f-bf1f-9974c9cccb53\"\n",
        "]\n",
        "\n",
        "\n",
        "encodings = ['utf8', 'ISO-8859-1', 'utf-8-sig', 'windows-1252']\n",
        "separators = [';', ',', ',', ',']\n",
        "files_names = [\"centres_vaccinations\", \"allocations_vs_rdv\", \"prise_rdv_par_centre\", \"stock\"]\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "    try:\n",
        "        df = pd.read_csv(url, sep=separators[i], header=0, encoding=encodings[i], dtype={'departement': str})\n",
        "        table_name = files_names[i]\n",
        "        load_dataframe_to_snowflake(df, table_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors de la lecture ou du chargement du fichier {i+1} : {e}\")\n",
        "\n",
        "# Fermer la connexion\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLs1DgwnFmnj",
        "outputId": "d8339d74-ca36-4287-9df5-a4b90a84f0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement réussi de 3211 lignes dans la table centres_vaccinations.\n",
            "Chargement réussi de 3564 lignes dans la table allocations_vs_rdv.\n",
            "Chargement réussi de 99405 lignes dans la table prise_rdv_par_centre.\n",
            "Chargement réussi de 749 lignes dans la table stock.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import snowflake.connector\n",
        "from snowflake.connector.pandas_tools import write_pandas\n",
        "from google.colab import userdata\n",
        "\n",
        "# Créer une connexion à Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    user=userdata.get('SNOWFLAKE_USER'),\n",
        "    password=userdata.get('SNOWFLAKE_PASSWORD'),\n",
        "    account=userdata.get('SNOWFLAKE_ACCOUNT'),\n",
        "    warehouse=userdata.get('SNOWFLAKE_WAREHOUSE'),\n",
        "    database=userdata.get('SNOWFLAKE_DATABASE'),\n",
        "    schema=userdata.get('SNOWFLAKE_SCHEMA')\n",
        ")\n",
        "\n",
        "# Fonction pour charger un DataFrame dans Snowflake\n",
        "def load_dataframe_to_snowflake(df, table_name):\n",
        "    # Remove double quotes from column names to avoid case-sensitivity issues\n",
        "    df.columns = [col.replace('\"', '') for col in df.columns]\n",
        "\n",
        "    # Convert column names to uppercase because Snowflake column names are uppercase by default\n",
        "    df.columns = df.columns.str.upper()\n",
        "\n",
        "    success, nchunks, nrows, _ = write_pandas(conn, df, table_name.upper(), auto_create_table=True)\n",
        "    print(f\"Chargement réussi de {nrows} lignes dans la table {table_name}.\")\n",
        "\n",
        "urls = [\"https://www.data.gouv.fr/fr/datasets/r/dbe8a621-a9c4-4bc3-9cae-be1699c5ff25\"]\n",
        "\n",
        "encodings = ['utf-8-sig']\n",
        "separators = [ ',']\n",
        "files_names = [\"dim_france_reg_dpt_zip\"]\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "    try:\n",
        "        df = pd.read_csv(url, sep=separators[i], header=0, encoding=encodings[i], dtype={'departement': str})\n",
        "        table_name = files_names[i]\n",
        "        load_dataframe_to_snowflake(df, table_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors de la lecture ou du chargement du fichier {i+1} : {e}\")\n",
        "\n",
        "# Fermer la connexion\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5K41lfxOwzr",
        "outputId": "fd01c798-3383-473c-b890-c53b86f1ca47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement réussi de 39201 lignes dans la table dim_france_reg_dpt_zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import snowflake.connector\n",
        "from snowflake.connector.pandas_tools import write_pandas\n",
        "from google.colab import userdata\n",
        "\n",
        "# Créer une connexion à Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    user=userdata.get('SNOWFLAKE_USER'),\n",
        "    password=userdata.get('SNOWFLAKE_PASSWORD'),\n",
        "    account=userdata.get('SNOWFLAKE_ACCOUNT'),\n",
        "    warehouse=userdata.get('SNOWFLAKE_WAREHOUSE'),\n",
        "    database=userdata.get('SNOWFLAKE_DATABASE'),\n",
        "    schema=userdata.get('SNOWFLAKE_SCHEMA')\n",
        ")\n",
        "\n",
        "# Fonction pour charger un DataFrame dans Snowflake\n",
        "def load_dataframe_to_snowflake(df, table_name):\n",
        "    # Remove double quotes from column names to avoid case-sensitivity issues\n",
        "    df.columns = [col.replace('\"', '') for col in df.columns]\n",
        "\n",
        "    # Convert column names to uppercase because Snowflake column names are uppercase by default\n",
        "    df.columns = df.columns.str.upper()\n",
        "\n",
        "    success, nchunks, nrows, _ = write_pandas(conn, df, table_name.upper(), auto_create_table=True)\n",
        "    print(f\"Chargement réussi de {nrows} lignes dans la table {table_name}.\")\n",
        "\n",
        "urls = [\"https://www.data.gouv.fr/fr/datasets/r/dc2fd531-2314-44bb-b0a9-39e621e4b12c\"]\n",
        "\n",
        "encodings = ['utf-8-sig']\n",
        "separators = [ ',']\n",
        "files_names = [\"PRISE_RDV_PAR_CENTRE\"]\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "    try:\n",
        "        df = pd.read_csv(url, sep=separators[i], header=0, encoding=encodings[i], dtype={'departement': str})\n",
        "        table_name = files_names[i]\n",
        "        load_dataframe_to_snowflake(df, table_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors de la lecture ou du chargement du fichier {i+1} : {e}\")\n",
        "\n",
        "# Fermer la connexion\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9naoY-X7Ziz-",
        "outputId": "cd970d06-644c-4924-8a24-85e1d3d8178d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement réussi de 99405 lignes dans la table PRISE_RDV_PAR_CENTRE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import snowflake.connector\n",
        "from snowflake.connector.pandas_tools import write_pandas\n",
        "from google.colab import userdata\n",
        "\n",
        "# Créer une connexion à Snowflake\n",
        "conn = snowflake.connector.connect(\n",
        "    user=userdata.get('SNOWFLAKE_USER'),\n",
        "    password=userdata.get('SNOWFLAKE_PASSWORD'),\n",
        "    account=userdata.get('SNOWFLAKE_ACCOUNT'),\n",
        "    warehouse=userdata.get('SNOWFLAKE_WAREHOUSE'),\n",
        "    database=userdata.get('SNOWFLAKE_DATABASE'),\n",
        "    schema=userdata.get('SNOWFLAKE_SCHEMA')\n",
        ")\n",
        "\n",
        "# Fonction pour charger un DataFrame dans Snowflake\n",
        "def load_dataframe_to_snowflake(df, table_name):\n",
        "    # Remove double quotes from column names to avoid case-sensitivity issues\n",
        "    df.columns = [col.replace('\"', '') for col in df.columns]\n",
        "\n",
        "    # Convert column names to uppercase because Snowflake column names are uppercase by default\n",
        "    df.columns = df.columns.str.upper()\n",
        "\n",
        "    success, nchunks, nrows, _ = write_pandas(conn, df, table_name.upper(), auto_create_table=True)\n",
        "    print(f\"Chargement réussi de {nrows} lignes dans la table {table_name}.\")\n",
        "\n",
        "urls = [\"https://datavaccin-covid.ameli.fr/api/explore/v2.1/catalog/datasets/donnees-vaccination-lieu-de-vaccination/exports/csv?lang=fr&timezone=Europe%2FBerlin&use_labels=true&delimiter=%3B\"]\n",
        "\n",
        "encodings = ['utf-8-sig']\n",
        "separators = [ ';']\n",
        "files_names = [\"VACCINATION_PAR_LIEU\"]\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "    try:\n",
        "        df = pd.read_csv(url, sep=separators[i], header=0, encoding=encodings[i], dtype={'departement': str})\n",
        "        table_name = files_names[i]\n",
        "        load_dataframe_to_snowflake(df, table_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors de la lecture ou du chargement du fichier {i+1} : {e}\")\n",
        "\n",
        "# Fermer la connexion\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwGPouz4yb_V",
        "outputId": "c32d2815-113c-4bf2-ea52-c6900cfda8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement réussi de 636 lignes dans la table VACCINATION_PAR_LIEU.\n"
          ]
        }
      ]
    }
  ]
}